{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing-v0\n",
    "\n",
    "https://gymnasium.farama.org/environments/box2d/car_racing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Score: -35.691318327974834\n",
      "Episode: 2 Score: -34.93150684931565\n",
      "Episode: 3 Score: -35.27508090614943\n",
      "Episode: 4 Score: -31.972789115646755\n",
      "Episode: 5 Score: -38.11074918566834\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CarRacing-v2\")\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    observation, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "    \n",
    "    while not terminated and not truncated:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode} Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], 1.0, (3,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41892081, 0.42488927, 0.60337555], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (96, 96, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[106,  49, 132],\n",
       "        [212,  58,  82],\n",
       "        [161,  41, 211],\n",
       "        ...,\n",
       "        [ 71, 114, 207],\n",
       "        [252, 174,  83],\n",
       "        [150,  56,  56]],\n",
       "\n",
       "       [[ 16, 207,  43],\n",
       "        [ 59, 162,  29],\n",
       "        [194,  63, 145],\n",
       "        ...,\n",
       "        [ 54, 192, 126],\n",
       "        [139, 174,  84],\n",
       "        [179, 115, 193]],\n",
       "\n",
       "       [[149,  14,  99],\n",
       "        [214, 140,  83],\n",
       "        [104,  45,  76],\n",
       "        ...,\n",
       "        [ 41,  32, 161],\n",
       "        [ 75, 226, 199],\n",
       "        [233,  84,  72]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[136,   4, 241],\n",
       "        [  4, 197, 184],\n",
       "        [ 86, 201, 170],\n",
       "        ...,\n",
       "        [ 81, 118, 247],\n",
       "        [145, 247,  33],\n",
       "        [130,  23,  86]],\n",
       "\n",
       "       [[239, 142,  43],\n",
       "        [ 28, 202, 155],\n",
       "        [159, 211,  19],\n",
       "        ...,\n",
       "        [145, 210, 164],\n",
       "        [ 33, 228, 126],\n",
       "        [  5,  48,  15]],\n",
       "\n",
       "       [[153, 144,  44],\n",
       "        [189, 225, 163],\n",
       "        [246, 183,  66],\n",
       "        ...,\n",
       "        [160,  47, 241],\n",
       "        [ 85, 100,  28],\n",
       "        [ 79, 177,  31]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs_2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs_2') # Path: Training/Logs\n",
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs_2\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 15   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 132  |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043052514 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.0802       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.705        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 0.893        |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 502          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068573225 |\n",
      "|    clip_fraction        | 0.0768       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.0957       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.472        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002783041 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.0994      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.599       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.000365    |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 844          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063558975 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.83        |\n",
      "|    explained_variance   | 0.0496       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 976          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013419983 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.83        |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000833    |\n",
      "|    std                  | 0.874        |\n",
      "|    value_loss           | 4.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1181         |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022919583 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 4.61         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1317         |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069475286 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.79        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.852        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1538        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007733821 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | -0.182      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.43        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 1690       |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00575687 |\n",
      "|    clip_fraction        | 0.0829     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | -0.056     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.8        |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00324   |\n",
      "|    std                  | 0.845      |\n",
      "|    value_loss           | 3.52       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1872         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036930388 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.74        |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 2001        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005914023 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 2204         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054077464 |\n",
      "|    clip_fraction        | 0.0731       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.73        |\n",
      "|    explained_variance   | -0.0657      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 3.82         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 2345         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057375496 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.71         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 2544         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070181135 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.71        |\n",
      "|    explained_variance   | -0.0433      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.96         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    std                  | 0.836        |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2707        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003773893 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | -0.0465     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    std                  | 0.832       |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 11         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 2922       |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00484842 |\n",
      "|    clip_fraction        | 0.0432     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.7       |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 66.7       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.000614  |\n",
      "|    std                  | 0.833      |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 3063         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075320844 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.69        |\n",
      "|    explained_variance   | -0.0403      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.32         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 3279         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068521732 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000875    |\n",
      "|    std                  | 0.825        |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 3417        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005512527 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -2.39e-05   |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 3637        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006988801 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.0646      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 0.814       |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 3801         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055749724 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | -0.0389      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.84         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000913    |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 10.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 4031        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007640589 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | -0.181      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.802       |\n",
      "|    value_loss           | 5.67        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 4209         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045786174 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.799        |\n",
      "|    value_loss           | 3.58         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 4425        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006820266 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.798       |\n",
      "|    value_loss           | 7.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 4620        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006959744 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.801       |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 4826         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057920064 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | -0.0951      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.62         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 5010        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005219268 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.0182      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.000488    |\n",
      "|    std                  | 0.784       |\n",
      "|    value_loss           | 6.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 5194        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004989572 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.00203     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000173   |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 6.53        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 5395         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052636107 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | -0.017       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.38         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000686    |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 5564         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007183325 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.00011      |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 5774        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005809256 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.000131    |\n",
      "|    std                  | 0.771       |\n",
      "|    value_loss           | 7.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 5943        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005072278 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.89        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.763       |\n",
      "|    value_loss           | 7.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 6150        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006920445 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.66        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.767       |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 6283        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006292856 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 0.764       |\n",
      "|    value_loss           | 7.35        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 6469         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047949813 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.762        |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 6625         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065907612 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    std                  | 0.764        |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 6820         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011188586 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | -0.429       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.52         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000417    |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 12.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 6959         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061300355 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.44        |\n",
      "|    explained_variance   | -0.0682      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 0.76         |\n",
      "|    value_loss           | 5.16         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 7169        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007137671 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | -0.00101    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.12        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 9           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 7321         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049250005 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.756        |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 7551        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013479464 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 7701        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004941307 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 7902        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003530895 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | -0.366      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    std                  | 0.755       |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 8034         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081054745 |\n",
      "|    clip_fraction        | 0.0591       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | 0.0124       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000284    |\n",
      "|    std                  | 0.754        |\n",
      "|    value_loss           | 4.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 8233        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005029316 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 8362        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009173634 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | -0.746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.97        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 8591         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048707877 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.41        |\n",
      "|    explained_variance   | -0.0974      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.82         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000285    |\n",
      "|    std                  | 0.754        |\n",
      "|    value_loss           | 8.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 8726         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044365562 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.4         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    std                  | 0.752        |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22ea5ec04c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', 'PPO_Model_CarRacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\se99a\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mCarRacing-v2\u001b[39m\u001b[39m\"\u001b[39m, render_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m evaluate_policy(model, env, n_eval_episodes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m env\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mwhile\u001b[39;00m (episode_counts \u001b[39m<\u001b[39m episode_count_targets)\u001b[39m.\u001b[39many():\n\u001b[0;32m     88\u001b[0m     actions, states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m     89\u001b[0m         observations,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         state\u001b[39m=\u001b[39mstates,\n\u001b[0;32m     91\u001b[0m         episode_start\u001b[39m=\u001b[39mepisode_starts,\n\u001b[0;32m     92\u001b[0m         deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 94\u001b[0m     new_observations, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[0;32m     95\u001b[0m     current_rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rewards\n\u001b[0;32m     96\u001b[0m     current_lengths \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:553\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworld\u001b[39m.\u001b[39mStep(\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS, \u001b[39m6\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[0;32m    551\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS\n\u001b[1;32m--> 553\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render(\u001b[39m\"\u001b[39;49m\u001b[39mstate_pixels\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    555\u001b[0m step_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    556\u001b[0m terminated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:617\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    614\u001b[0m trans \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[39m.\u001b[39mrotate_rad(angle)\n\u001b[0;32m    615\u001b[0m trans \u001b[39m=\u001b[39m (WINDOW_W \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m0\u001b[39m], WINDOW_H \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m1\u001b[39m])\n\u001b[1;32m--> 617\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_road(zoom, trans, angle)\n\u001b[0;32m    618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcar\u001b[39m.\u001b[39mdraw(\n\u001b[0;32m    619\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf,\n\u001b[0;32m    620\u001b[0m     zoom,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m     mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mstate_pixels_list\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstate_pixels\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    624\u001b[0m )\n\u001b[0;32m    626\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mflip(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:687\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[1;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[0;32m    685\u001b[0m poly \u001b[39m=\u001b[39m [(p[\u001b[39m0\u001b[39m], p[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m poly]\n\u001b[0;32m    686\u001b[0m color \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m color]\n\u001b[1;32m--> 687\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_draw_colored_polygon(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf, poly, color, zoom, translation, angle)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:774\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[1;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39m# This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[39m# Instead of calculating exactly if the polygon and screen overlap,\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[39m# we simply check if the polygon is in a larger bounding box whose dimension\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[39m# is greater than the screen by MAX_SHAPE_DIM, which is the maximum\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[39m# diagonal length of an environment object\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m clip \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    770\u001b[0m     (\u001b[39m-\u001b[39mMAX_SHAPE_DIM \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m coord[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m WINDOW_W \u001b[39m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    771\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39m-\u001b[39mMAX_SHAPE_DIM \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m coord[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m WINDOW_H \u001b[39m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    772\u001b[0m     \u001b[39mfor\u001b[39;00m coord \u001b[39min\u001b[39;00m poly\n\u001b[0;32m    773\u001b[0m ):\n\u001b[1;32m--> 774\u001b[0m     gfxdraw\u001b[39m.\u001b[39;49maapolygon(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf, poly, color)\n\u001b[0;32m    775\u001b[0m     gfxdraw\u001b[39m.\u001b[39mfilled_polygon(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, poly, color)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", render_mode='human')\n",
    "evaluate_policy(model, env, n_eval_episodes=10)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6043579 ,  0.05329743,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(observation)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v2\", render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m terminated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m truncated:\n\u001b[0;32m      9\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(observation)\n\u001b[1;32m---> 10\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     11\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m}\u001b[39;00m\u001b[39m Score: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:553\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworld\u001b[39m.\u001b[39mStep(\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS, \u001b[39m6\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[0;32m    551\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m FPS\n\u001b[1;32m--> 553\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render(\u001b[39m\"\u001b[39;49m\u001b[39mstate_pixels\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    555\u001b[0m step_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    556\u001b[0m terminated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:618\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    615\u001b[0m trans \u001b[39m=\u001b[39m (WINDOW_W \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m0\u001b[39m], WINDOW_H \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \u001b[39m+\u001b[39m trans[\u001b[39m1\u001b[39m])\n\u001b[0;32m    617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render_road(zoom, trans, angle)\n\u001b[1;32m--> 618\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcar\u001b[39m.\u001b[39;49mdraw(\n\u001b[0;32m    619\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf,\n\u001b[0;32m    620\u001b[0m     zoom,\n\u001b[0;32m    621\u001b[0m     trans,\n\u001b[0;32m    622\u001b[0m     angle,\n\u001b[0;32m    623\u001b[0m     mode \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mstate_pixels_list\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstate_pixels\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    624\u001b[0m )\n\u001b[0;32m    626\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mflip(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    628\u001b[0m \u001b[39m# showing stats\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\se99a\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_dynamics.py:268\u001b[0m, in \u001b[0;36mCar.draw\u001b[1;34m(self, surface, zoom, translation, angle, draw_particles)\u001b[0m\n\u001b[0;32m    258\u001b[0m         w\u001b[39m.\u001b[39momega \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m dt \u001b[39m*\u001b[39m f_force \u001b[39m*\u001b[39m w\u001b[39m.\u001b[39mwheel_rad \u001b[39m/\u001b[39m WHEEL_MOMENT_OF_INERTIA\n\u001b[0;32m    260\u001b[0m         w\u001b[39m.\u001b[39mApplyForceToCenter(\n\u001b[0;32m    261\u001b[0m             (\n\u001b[0;32m    262\u001b[0m                 p_force \u001b[39m*\u001b[39m side[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m f_force \u001b[39m*\u001b[39m forw[\u001b[39m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m         )\n\u001b[1;32m--> 268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw\u001b[39m(\u001b[39mself\u001b[39m, surface, zoom, translation, angle, draw_particles\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    269\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpygame\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdraw\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m draw_particles:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    observation, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "    \n",
    "    while not terminated and not truncated:\n",
    "        action, _ = model.predict(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode} Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1, dtype=int64), None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs = obs[0]\n",
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03060195,  0.1461695 , -0.02986192, -0.29166082], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
